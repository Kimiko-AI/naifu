target: modules.SFT_Lumina.setup
adaptive_loss_weight: True
name: test-run

lightning:
  precision: "16-mixed"

trainer:
  model_path: ""
  resolution: 256
  batch_size: 1
  checkpoint_dir: "checkpoints/lumina_gradient"
  save_every: 1000
  grad_clip: 1.0
  max_steps: 10000
  seed: 42
  wandb_id: "Lumina_test"
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  checkpoint_steps: 1000
  checkpoint_freq: 1
  save_weights_only: false
  max_epochs: -1
  auto_resume: false


model:
  vae_path: "REPA-E/e2e-flux-vae"
  tokenizer_path: "unsloth/gemma-3-270m-it"
  text_encoder_path: "unsloth/gemma-3-270m-it"




dataset:
  name: "data.gradient.TagImageDataset"
  image_size: 256
  dataset_path: "animetimm/danbooru-wdtagger-v4-w640-ws-50k"
  batch_size: 16

optimizer:
  name: "torch.optim.AdamW"
  params:
    lr: 1.0e-5
    weight_decay: 0.01

scheduler:
  name: "torch.optim.lr_scheduler.CosineAnnealingLR"
  params:
    T_max: 10000

advanced:
  train_text_encoder: False
  snr_type: "lognorm"
  no_shift: true
  use_ema: true


sampling:
  enabled: False
  every_n_steps: 1000
  every_n_epochs: 1
  prompts:
    - "a gradient from black to white"
  save_dir: "samples/lumina_gradient"
  seed: 42